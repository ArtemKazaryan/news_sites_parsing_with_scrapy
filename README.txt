1. Откройте папку с проектом в PyCharm или VSCode.
2. Откройте терминал.
3. Для перехода в папку запуска Введите команду cd newsparse/newsparse/spiders и нажмите ENTER.
4. Для запуска процесса парсинга введите команду scrapy crawl news_spider и нажмите ENTER.
5. В терминале появится меню, в котором Вам будет предложен выбор. Укажите выбранный пункт и нажмите ENTER.
6. При выборе одного из сайтов запустится кроулинг и потребуется выждать некоторое время, которое зависит от выставленных параметров сайта в yaml файле с настройками для парсинга каждого сайта.
7. По окончании данные по новостям запишутся в таблицу items базы данных parsenewse.db, которые можно просмотреть в SQLiteStudio, например.
8. Если потребуется дополнительная запись данных в файл json, то такая команда как scrapy crawl news_spider -O news.jsonв запишет данные в файл news.json.
10. Предусмотренно удаление данных из таблицы items БД в SQLiteStudio командой 'DELETE FROM' items в окне редактора (Alt+E)
